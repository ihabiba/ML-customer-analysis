# Customer Analytics with Machine Learning

This project combines **Supervised** and **Unsupervised Machine Learning** techniques to analyze customer behavior. It includes:

* **Customer Churn Prediction** (Supervised Learning)
* **Customer Segmentation** (Unsupervised Learning)

Both analyses are performed on real-world datasets and supported by extensive visualizations.

---

## ğŸ“Œ Project Structure

```
ML-customer-analysis/
â”œâ”€â”€ supervised.ipynb          # Churn prediction (Supervised ML)
â”œâ”€â”€ Unsupervised.ipynb        # Customer segmentation (Unsupervised ML)
â”œâ”€â”€ assets/                   # All generated plots and visuals
â””â”€â”€ Datasets.zip              # Telco + E-commerce datasets
```

---

## ğŸ“Š 1. Customer Churn Prediction (Supervised Learning)

Using the **Telco Customer Churn** dataset, the notebook performs end-to-end predictive modeling.

### ğŸ”¹ Steps Performed

* **Data Cleaning** (handling missing values in `TotalCharges`)
* **Label Encoding** (binary categorical features)
* **Oneâ€‘Hot Encoding** (InternetService, Contract, PaymentMethod)
* **Feature Scaling** (StandardScaler)
* **Feature Selection** using **RFECV** â†’ **18 optimal features**
* **Model Training & Evaluation** using:

  * Logistic Regression
  * Kâ€‘Nearest Neighbors (k=12)
  * Decision Tree (raw)
  * Decision Tree (preâ€‘pruned via GridSearchCV)
  * Support Vector Machine (Linear kernel)

### ğŸ“ˆ Model Performance

| Model                      | Accuracy   | F1 (Churn=1) |
| -------------------------- | ---------- | ------------ |
| **Logistic Regression**    | **0.8024** | **0.59**     |
| SVM (Linear)               | 0.7953     | 0.58         |
| Decision Tree (Preâ€‘Pruned) | 0.7853     | 0.57         |
| KNN (k=12)                 | 0.7844     | 0.54         |
| Decision Tree (No Pruning) | 0.7246     | 0.47         |

### ğŸ” Visualizations

All located in `assets/`:

* Confusion Matrix Heatmap
* ROC Curves (all models)
* Precisionâ€“Recall Curves
* Random Forest Feature Importance
* SHAP Summary Plot

### ğŸ’¡ Key Insights

* **Logistic Regression** performs best overall.
* Strong churn indicators include:

  * High MonthlyCharges
  * Short tenure
  * Monthâ€‘toâ€‘month contracts
  * Electronic check payments
  * Lack of OnlineSecurity

---

## ğŸ§© 2. Customer Segmentation (Unsupervised Learning)

Using an **eâ€‘commerce transactions dataset**, the notebook builds meaningful customer segments.

### ğŸ”¹ Steps Performed

* Dropping missing values
* Feature engineering from `InvoiceDate`:

  * Hour, Day, Month, Weekday
* Oneâ€‘Hot Encoding for `Country`
* Frequency encoding for StockCode & InvoiceNo
* Scaling with StandardScaler
* Dimensionality Reduction with PCA (95% variance â†’ 22 components)

### ğŸ§® Kâ€‘Means Clustering

* **Elbow Method** â†’ visual inertia drop
* **Silhouette Scores** â†’ best at **K = 3**
* Clusters labeled as:

  * **Low Spenders**
  * **Regular Customers**
  * **Highâ€‘Value Customers**

### ğŸ“Š Visualizations

Found in `assets/`:

* Scree Plot (PCA variance)
* Elbow Plot
* Silhouette Score Bar Chart
* Cluster Size Distribution
* Bar Chart (Quantity vs Estimated Spend)
* PCA 2D Scatter Plot (PC1 vs PC2)
* PCA 3D Scatter Plot (PC1â€“PC3)

### ğŸ’¡ Segment Insights

* **Highâ€‘Value customers** purchase larger quantities at higher price points.
* **Low Spenders** show minimal purchase volume.
* **Regular customers** fall in between with stable buying patterns.

---

## ğŸ› ï¸ Technologies Used

* Python
* Pandas
* NumPy
* Scikitâ€‘learn
* Matplotlib
* Seaborn
* SHAP

---

## âœ”ï¸ Summary

This project applies machine learning to uncover **why customers churn** and **how customers group into behavioral segments**, using real datasets and strong model evaluation. It demonstrates endâ€‘toâ€‘end ML capability: preprocessing, feature selection, clustering, classification, and explainability.

---
